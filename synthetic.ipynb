{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d91e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from helper import *\n",
    "from calculate_delta import *\n",
    "import sys\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import os\n",
    "from drmv_riskfree import *\n",
    "\n",
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec163382",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_real = np.load('real_data_sigma.npy')\n",
    "df=pd.read_csv('df_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a449a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_mkt_data_highdim(T, num_paths, \n",
    "                         sigma, s0, dt=1/252, seed=1):\n",
    "    \"\"\"\n",
    "    使用联合离散分布，模拟高维市场数据。\n",
    "\n",
    "    参数:\n",
    "        T (float): 总模拟时间 (例如，1.0 代表一年)。\n",
    "        joint_z_vectors (ndarray): 预定义的场景向量，形状为 (m, dim)。\n",
    "        p_dist (ndarray): 每个场景向量对应的概率，形状为 (m,)。\n",
    "        num_paths (int): 要模拟的路径数量。\n",
    "        sigma (ndarray): **波动率矩阵 σ**，形状为 (dim, dim)。\n",
    "        s0 (float): 初始价格。  \n",
    "        dt (float): 时间步长。\n",
    "\n",
    "    返回:\n",
    "        S (ndarray): 模拟的股价路径，形状 (num_paths, N+1, dim)。\n",
    "        t_list (ndarray): 时间点列表，形状 (N+1,)。\n",
    "        b_vectors (ndarray): 为每条路径选择的漂移向量，形状 (num_paths, dim)。\n",
    "        W (ndarray): 模拟的多维布朗运动，形状 (num_paths, N+1, dim)。\n",
    "    \"\"\"\n",
    "    dim = sigma.shape[0]\n",
    "    N = int(T / dt)  # 时间步数量\n",
    "    t_list = np.linspace(0, T, N + 1)\n",
    "    np.random.seed(seed)\n",
    "    # --- Bt=B0*(1+np.cos(2*np.pi*rand_k*t)) /2---\n",
    "    # 抽取 m 个场景的索引\n",
    "    # num_scenarios = joint_z_vectors.shape[0]\n",
    "    # scenario_indices = np.arange(num_scenarios)\n",
    "    # chosen_indices = np.random.choice(scenario_indices, p=p_dist, size=num_paths, replace=True)\n",
    "\n",
    "\n",
    "    B0=0.2\n",
    "    rand_k = np.random.normal(10, 30, sigma.shape[0]) # TODO: make k larger so fluctuate weekly or bi-weekly; can change to fixed numbers rather than random\n",
    "    # generate b_vectors, finally shape is (N, dim)\n",
    "    b_vectors = np.zeros((N, dim))\n",
    "    \n",
    "    # Create meshgrid for proper broadcasting: t (N,) and rand_k (dim,)\n",
    "    # We use t_list[:-1] to get N time steps (excluding the last one)\n",
    "    t_mesh, rand_k_mesh = np.meshgrid(t_list[:-1], rand_k, indexing='ij')\n",
    "    # Now t_mesh and rand_k_mesh both have shape (N, dim)\n",
    "    b_vectors = B0*(1 + 2*np.cos(2*np.pi*rand_k_mesh*t_mesh))/2\n",
    "\n",
    "    # --- 2. 模拟多维布朗运动 W ---\n",
    "    # 生成标准正态分布的增量\n",
    "    \n",
    "    normal_increments = np.random.normal(loc=0.0, scale=np.sqrt(dt), size=(num_paths, N, dim))\n",
    "    \n",
    "    W = np.zeros((num_paths, N + 1, dim))\n",
    "    # 通过对增量进行累积求和来构建布朗运动路径\n",
    "    W[:, 1:, :] = np.cumsum(normal_increments, axis=1)\n",
    "\n",
    "    # --- 3. 模拟股价路径 S ---\n",
    "    S = np.zeros((num_paths, N + 1, dim))\n",
    "\n",
    "    S[:, 0, :] = s0 * np.ones((num_paths, dim))\n",
    "\n",
    "    for i in range(N):\n",
    "        # 提取当前状态\n",
    "        current_S = S[:, i, :]\n",
    "        \n",
    "        # 布朗运动的增量 dW\n",
    "        dW = W[:, i + 1, :] - W[:, i, :]\n",
    "        \n",
    "        # --- 计算 SDE 的增量 dS ---\n",
    "        # 漂移项: b*dt\n",
    "        drift_term = b_vectors[i] * dt\n",
    "        \n",
    "        # 波动率项: σ * dW\n",
    "        # 使用矩阵乘法 (@)，并对 sigma 进行转置以匹配批量操作的维度\n",
    "        # (num_paths, dim) @ (dim, dim) -> (num_paths, dim)\n",
    "        vol_term = dW @ sigma.T\n",
    "        \n",
    "        # 逐元素乘法计算 dS\n",
    "        dS = current_S * (drift_term + vol_term)\n",
    "        \n",
    "        # 更新下一时间步的价格\n",
    "        S[:, i + 1, :] = current_S + dS\n",
    "    \n",
    "    # for each path, if any negative items in S, remove this path \n",
    "    for i in range(num_paths):\n",
    "        if np.any(S[i] < 0):\n",
    "            S = np.delete(S, i, axis=0)\n",
    "            W = np.delete(W, i, axis=0)\n",
    "    \n",
    "    \n",
    "    return S, t_list, b_vectors, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2414119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3025, 20)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_gen, t_list_gen, b_vectors_gen, W_gen = sim_mkt_data_highdim(T=12, num_paths=100, s0=10, sigma=sigma_real, dt=1/252)\n",
    "prices_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18162073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data_to_df(prices, real_trade_dates, types=60):\n",
    "    \"\"\"\n",
    "    Converts a 2D numpy array of prices into a long-format pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        prices (np.ndarray): A 2D numpy array of shape (T, dim), where T is the\n",
    "                             number of time periods and dim is the number of stocks.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns: 'date', 'permno', 'ret', and 'prc'.\n",
    "                      'permno' is the stock identifier, from 1 to dim.\n",
    "    \"\"\"\n",
    "    T, dim = prices.shape\n",
    "    dates = real_trade_dates[-T:]\n",
    "    permnos = range(1, dim + 1)\n",
    "\n",
    "    # Create a wide DataFrame for prices\n",
    "    df_prc = pd.DataFrame(prices, index=dates, columns=permnos)\n",
    "    df_prc.index.name = 'date'\n",
    "    df_prc.columns.name = 'permno'\n",
    "\n",
    "    # Calculate returns\n",
    "    df_ret = df_prc.pct_change()\n",
    "\n",
    "    # Stack prices and returns to convert to long format\n",
    "    # dropna=False is important to keep all price entries, even with NaN returns for the first day\n",
    "    s_prc = df_prc.stack(dropna=False).rename('prc')\n",
    "    s_ret = df_ret.stack(dropna=False).rename('ret')\n",
    "\n",
    "    # Combine into a single DataFrame, aligning on the (date, permno) index\n",
    "    df = pd.concat([s_ret, s_prc], axis=1)\n",
    "\n",
    "    # Reset index to get 'date' and 'permno' as columns\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Reorder columns to the desired format\n",
    "    df = df[['date', 'permno', 'ret', 'prc']]\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['type'] = (df.groupby('date').ngroup() % types) + 1\n",
    "    df['prc_adjusted'] = df['prc']\n",
    "    df['log_ret'] = df.groupby('permno')['prc'].transform(lambda x: np.log(x / x.shift(1)))\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2b4d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = sim_data_to_df(prices_gen[0], df['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddf32474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>ret</th>\n",
       "      <th>prc</th>\n",
       "      <th>type</th>\n",
       "      <th>prc_adjusted</th>\n",
       "      <th>log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>9.789018</td>\n",
       "      <td>2</td>\n",
       "      <td>9.789018</td>\n",
       "      <td>-0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.019481</td>\n",
       "      <td>9.897384</td>\n",
       "      <td>2</td>\n",
       "      <td>9.897384</td>\n",
       "      <td>-0.019674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>9.888227</td>\n",
       "      <td>2</td>\n",
       "      <td>9.888227</td>\n",
       "      <td>-0.013523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>10.297934</td>\n",
       "      <td>2</td>\n",
       "      <td>10.297934</td>\n",
       "      <td>0.023384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>10.109208</td>\n",
       "      <td>2</td>\n",
       "      <td>10.109208</td>\n",
       "      <td>-0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60455</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>39.044854</td>\n",
       "      <td>24</td>\n",
       "      <td>39.044854</td>\n",
       "      <td>0.005755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60456</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.013081</td>\n",
       "      <td>32.298023</td>\n",
       "      <td>24</td>\n",
       "      <td>32.298023</td>\n",
       "      <td>-0.013167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60457</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.021993</td>\n",
       "      <td>11.650680</td>\n",
       "      <td>24</td>\n",
       "      <td>11.650680</td>\n",
       "      <td>-0.022239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60458</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.022032</td>\n",
       "      <td>42.341205</td>\n",
       "      <td>24</td>\n",
       "      <td>42.341205</td>\n",
       "      <td>-0.022279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60459</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.018210</td>\n",
       "      <td>48.934574</td>\n",
       "      <td>24</td>\n",
       "      <td>48.934574</td>\n",
       "      <td>-0.018378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60460 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  permno       ret        prc  type  prc_adjusted   log_ret\n",
       "0      2012-12-27       1 -0.002906   9.789018     2      9.789018 -0.002911\n",
       "1      2012-12-27       2 -0.019481   9.897384     2      9.897384 -0.019674\n",
       "2      2012-12-27       3 -0.013432   9.888227     2      9.888227 -0.013523\n",
       "3      2012-12-27       4  0.023659  10.297934     2     10.297934  0.023384\n",
       "4      2012-12-27       5 -0.001127  10.109208     2     10.109208 -0.001127\n",
       "...           ...     ...       ...        ...   ...           ...       ...\n",
       "60455  2024-12-31      16  0.005771  39.044854    24     39.044854  0.005755\n",
       "60456  2024-12-31      17 -0.013081  32.298023    24     32.298023 -0.013167\n",
       "60457  2024-12-31      18 -0.021993  11.650680    24     11.650680 -0.022239\n",
       "60458  2024-12-31      19 -0.022032  42.341205    24     42.341205 -0.022279\n",
       "60459  2024-12-31      20 -0.018210  48.934574    24     48.934574 -0.018378\n",
       "\n",
       "[60460 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aab903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sim_new(input_df, r=0.02, seed=42, start_date='2024-01-01', end_date='2024-12-31',\n",
    "                 beta=-3, num_stocks=20, plan_time=1/12):\n",
    "    # Step 1: Load data\n",
    "    \n",
    "    df = input_df\n",
    "    \n",
    "    # Sort by permno and date to ensure proper ordering for log return calculation\n",
    "    df = df.sort_values(['permno', 'date'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Calculate log returns for each stock\n",
    "    \n",
    "    \n",
    "    # Step 1: Find stocks with complete data from 2005-12-31 to 2015-01-01\n",
    "    initial_start = pd.to_datetime(start_date) - relativedelta(years=10)    \n",
    "    initial_end = pd.to_datetime(start_date) - pd.Timedelta(days=1)\n",
    "    \n",
    "    # Get stocks that have data in the initial period\n",
    "    initial_period_data = df[(df['date'] >= initial_start) & (df['date'] <= initial_end)]\n",
    "    \n",
    "    # Count trading days in the initial period for validation\n",
    "    total_trading_days = initial_period_data['date'].nunique()\n",
    "    # print(f\"Total trading days in initial period: {total_trading_days}\")\n",
    "    \n",
    "    # Find stocks with sufficient data coverage (at least 80% of trading days)\n",
    "    stock_coverage = initial_period_data.groupby('permno')['date'].nunique()\n",
    "    min_required_days = int(total_trading_days)  # Require at least 80% coverage\n",
    "    valid_stocks_initial = stock_coverage[stock_coverage >= min_required_days].index.tolist()\n",
    "    \n",
    "    # print(f\"Stocks with sufficient data in initial period: {len(valid_stocks_initial)}\")\n",
    "    \n",
    "    # Sample num_stocks stocks from those with complete initial data\n",
    "    np.random.seed(seed)  # For reproducibility\n",
    "    selected_stocks = np.sort(np.random.choice(valid_stocks_initial, num_stocks, replace=False))\n",
    "    \n",
    "    print(f\"Initially selected stocks: {selected_stocks}\")\n",
    "    \n",
    "    # Step 2: Process monthly data starting from 2015-01-01\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    month_starts = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    \n",
    "    current_stocks = selected_stocks.copy()\n",
    "    kara_wealth_list = [1]\n",
    "    drbc_wealth_list = [1]\n",
    "    drmv_wealth_list = [1]\n",
    "    for i, current_month in enumerate(tqdm(month_starts)):\n",
    "        # print(f\"\\nProcessing month {i+1}/{len(month_starts)}: {current_month}\")\n",
    "        \n",
    "        # Define time windows\n",
    "        train_start = current_month - relativedelta(years=10)\n",
    "        train_end = current_month - pd.Timedelta(days=1)\n",
    "        test_start = current_month\n",
    "        test_end = month_starts[i+1] - pd.Timedelta(days=1) if i+1 < len(month_starts) else pd.to_datetime(end_date)\n",
    "        \n",
    "        # print(f\"Previous 10 years: {train_start.date()} to {train_end.date()}\")\n",
    "        # print(f\"Next month: {test_start.date()} to {test_end.date()}\")\n",
    "        \n",
    "        prev_to_next_dates = df[(df['date'] >= train_start) & (df['date'] <= test_end)]['date'].nunique()\n",
    "        \n",
    "        # Efficiently find all stocks with 100% coverage using vectorized operations\n",
    "        # Get data for the entire period (train + test)\n",
    "        full_period_start = train_start\n",
    "        full_period_end = test_end\n",
    "        full_period_data = df[(df['date'] >= full_period_start) & (df['date'] <= full_period_end)]\n",
    "        full_period_stock_dates = full_period_data.groupby('permno')['date'].nunique()\n",
    "        all_valid_stocks = full_period_stock_dates[full_period_stock_dates >= prev_to_next_dates].index.values\n",
    "        \n",
    "        # Check which current stocks are still valid\n",
    "        valid_current_stocks = np.intersect1d(current_stocks, all_valid_stocks)\n",
    "        \n",
    "        # print(f\"Current stocks with 100% coverage: {len(valid_current_stocks)} out of {len(current_stocks)}\")\n",
    "        # print(f\"Total stocks available with 100% coverage: {len(all_valid_stocks)}\")\n",
    "        \n",
    "        # If we need to replace stocks to maintain 20 stocks\n",
    "        stocks_needed = num_stocks - len(valid_current_stocks)\n",
    "        \n",
    "        if stocks_needed > 0:\n",
    "            # print(f\"Need to find {stocks_needed} replacement stocks\")\n",
    "            \n",
    "            # Find replacement candidates (exclude currently valid stocks)\n",
    "            replacement_candidates = np.setdiff1d(all_valid_stocks, valid_current_stocks)\n",
    "            \n",
    "            # print(f\"Available replacement candidates: {len(replacement_candidates)}\")\n",
    "            # add to 20 stocks\n",
    "            stocks_to_add = np.random.choice(replacement_candidates, stocks_needed, replace=False)\n",
    "            # Use all available replacements, even if less than needed\n",
    "            current_stocks = np.sort(np.concatenate([valid_current_stocks, stocks_to_add]))\n",
    "\n",
    "        else:\n",
    "            current_stocks = valid_current_stocks\n",
    "            # print(\"All current stocks are valid, no replacement needed\")\n",
    "        \n",
    "        # print(f\"Final stock selection for this month: {current_stocks}\")\n",
    "        # print(f\"Number of stocks: {len(current_stocks)}\")\n",
    "        \n",
    "        # Get training data for the selected stocks\n",
    "        pretrain_data = df[(df['date'] >= train_start) & (df['date'] <= train_end) & \n",
    "                          (df['permno'].isin(current_stocks))]\n",
    "        drmv_weights = run_single_backtest_select_stocks(\n",
    "            training_data=pretrain_data,\n",
    "            selected_perms=current_stocks,\n",
    "            annual_target_return=0.105,\n",
    "            r=r)\n",
    "        length = len(pretrain_data) / len(current_stocks)\n",
    "        prev_sigma_start_dt = (train_start - relativedelta(months=1))\n",
    "        #prev_sigma_start_dt = (train_start - relativedelta(years=1))\n",
    "        to_get_B_data = df[(df['date'] >= prev_sigma_start_dt) & (df['date'] <= train_end) & \n",
    "                          (df['permno'].isin(current_stocks))]\n",
    "        matrix = compute_annualized_matrix_type(to_get_B_data, sigma_real)\n",
    "        ret_matrix = pretrain_data.pivot(index='date', columns='permno', values='ret')\n",
    "        ret_matrix = ret_matrix.fillna(0)\n",
    "        \n",
    "       \n",
    "        # use real sigma matrix (already annualized)\n",
    "        sigma_mat = sigma_real #np.linalg.cholesky(cov)\n",
    "        curr_data = df[(df['date'] <= test_end) & (df['date'] >= current_month)&(df['permno'].isin(current_stocks))]\n",
    "        dt = 1/length\n",
    "        t_list = np.linspace(0, 1, 252)\n",
    "        price_st = curr_data.pivot(index='date', columns='permno', values='prc_adjusted').fillna(method='ffill').values\n",
    "        curr_all_ret = price_st[-1] / price_st[0] - 1\n",
    "        yt = St_to_Yt_vectorized(price_st[np.newaxis, :, :], price_st[0], sigma_mat, r, t_list[1:int(len(curr_data)/20)+1]) # can be t_list[0:len(curr_data)]\n",
    "        k= solve_k_with_EL(matrix, r=r, sigma=sigma_mat, T=plan_time, beta=beta, num_y=1000, seed=seed)\n",
    "\n",
    "        # calculate radius small delta (using 1 year, represents by T=1)\n",
    "        var = calculate_z_var(T=plan_time, r=r, sigma=sigma_mat, B_support=matrix, p_dist=np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k)\n",
    "        small_delta_array = (np.random.normal(0, np.sqrt(var), size=100)**2)*(calculate_numerator(plan_time, r, sigma_mat, matrix, np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k)/calculate_denominator(plan_time, r, sigma_mat, matrix, np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k))\n",
    "        small_delta = np.percentile(small_delta_array, 95)/40\n",
    "        \n",
    "        # calculate delta_B (using 1 year, represents by T=1)\n",
    "        delta_B = compute_big_delta_star(matrix, r, plan_time, beta, small_delta, sigma_mat)\n",
    "        \n",
    "        month_r = np.power(1+r, 1/12)-1 \n",
    "        # add month_r to curr_all_ret for drmv\n",
    "        curr_ret_for_drmv = np.append(curr_all_ret, month_r)\n",
    "        daily_kara = 1\n",
    "        daily_drbc = 1\n",
    "        daily_r = np.power(1+r, 1/252)-1\n",
    "        # last day not trade since no price for next day\n",
    "        for j in range(1,curr_data['date'].nunique()):\n",
    "            kara_frac_daily = pi_fraction_exact(t=j/252, Yt=yt[0][j-1], T=plan_time, alpha=beta, r=r, sigma=sigma_mat,\n",
    "                        joint_z_vectors=matrix, p_dist=np.ones(matrix.shape[0])/matrix.shape[0],\n",
    "                        num_expectation_samples=5000, seed=seed)\n",
    "            drbc_frac_daily = pi_fraction_exact(t=j/252, Yt=yt[0][j-1], T=plan_time, alpha=beta, r=r, sigma=sigma_mat, \n",
    "                        joint_z_vectors=matrix+delta_B, p_dist=np.ones(matrix.shape[0])/matrix.shape[0],\n",
    "                        num_expectation_samples=5000, seed=seed)\n",
    "            daily_kara *= (1-kara_frac_daily.sum())*daily_r+np.dot(kara_frac_daily, price_st[j] / price_st[j-1] - 1)+1\n",
    "            daily_drbc *= (1-drbc_frac_daily.sum())*daily_r+np.dot(drbc_frac_daily, price_st[j] / price_st[j-1] - 1)+1\n",
    "            \n",
    "            \n",
    "        # kara_wealth_list.append((kara_wealth_list[-1]*(1-kara_frac.sum())*month_r+np.dot(kara_frac, curr_all_ret)+1)*kara_wealth_list[-1])\n",
    "        # drbc_wealth_list.append((drbc_wealth_list[-1]*(1-drbc_frac.sum())*month_r+np.dot(drbc_frac, curr_all_ret)+1)*drbc_wealth_list[-1])\n",
    "        drmv_wealth_list.append(drmv_wealth_list[-1]*(1+np.dot(drmv_weights, curr_ret_for_drmv)))\n",
    "        kara_wealth_list.append(daily_kara*kara_wealth_list[-1])\n",
    "        drbc_wealth_list.append(daily_drbc*drbc_wealth_list[-1])\n",
    "\n",
    "    return kara_wealth_list, drbc_wealth_list, drmv_wealth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71c71b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially selected stocks: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:37<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "2.0327499353593144 1.9600649910721633 1.0804937557763217\n",
      "1.6823158177030693 1.7227479695613366 1.165670200025349\n",
      "0.41089515147638156 0.27787316850797283 1.0397435213526423\n",
      "0.5918342769139203 0.3530637853134173 1.0517148368631635\n",
      "0.6013019023317744 0.3498199233821997 1.0214441554111062\n",
      "1.2956916187511953 0.7490874368733822 1.0975901818773066\n",
      "1.8853872305004762 1.0099385751143073 1.1160251342779284\n",
      "1.5929720663559312 1.0592494103729453 1.1693711775042603\n",
      "0.6886371895667921 0.46251118911982897 1.3133484763060046\n",
      "0.9511840282689261 0.7888385669749719 1.3283877994198625\n",
      "2.0056133804820626 1.425579944667261 1.451914686316085\n",
      "0.9416294877031584 0.7341835702791033 1.2830782507657195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a = main_sim_new(sim_df)\n",
    "for i in range(len(a[0])):\n",
    "    print(a[0][i], a[1][i], a[2][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cd38d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
