{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a559e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3051.59s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: which: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `which'\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: _module_raw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_module_raw'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n"
     ]
    }
   ],
   "source": [
    "!conda list --export > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d91e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: _module_raw: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `_module_raw'\n",
      "sh: switchml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `switchml'\n",
      "sh: which: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `which'\n",
      "sh: module: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `module'\n",
      "sh: _module_raw: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `_module_raw'\n",
      "sh: switchml: line 1: syntax error: unexpected end of file\n",
      "sh: error importing function definition for `switchml'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpy2 setup and R function definition successful.\n",
      "Successfully fetched 'get_quantile' function from R environment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from helper import *\n",
    "from calculate_delta import *\n",
    "import sys\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import os\n",
    "from drmv_riskfree import *\n",
    "\n",
    "#autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec163382",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_real = np.load('real_data_sigma.npy')\n",
    "df=pd.read_csv('df_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a449a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_mkt_data_highdim(T, num_paths, \n",
    "                         sigma, s0, dt=1/252, seed=1):\n",
    "    \"\"\"\n",
    "    使用联合离散分布，模拟高维市场数据。\n",
    "\n",
    "    参数:\n",
    "        T (float): 总模拟时间 (例如，1.0 代表一年)。\n",
    "        joint_z_vectors (ndarray): 预定义的场景向量，形状为 (m, dim)。\n",
    "        p_dist (ndarray): 每个场景向量对应的概率，形状为 (m,)。\n",
    "        num_paths (int): 要模拟的路径数量。\n",
    "        sigma (ndarray): **波动率矩阵 σ**，形状为 (dim, dim)。\n",
    "        s0 (float): 初始价格。  \n",
    "        dt (float): 时间步长。\n",
    "\n",
    "    返回:\n",
    "        S (ndarray): 模拟的股价路径，形状 (num_paths, N+1, dim)。\n",
    "        t_list (ndarray): 时间点列表，形状 (N+1,)。\n",
    "        b_vectors (ndarray): 为每条路径选择的漂移向量，形状 (num_paths, dim)。\n",
    "        W (ndarray): 模拟的多维布朗运动，形状 (num_paths, N+1, dim)。\n",
    "    \"\"\"\n",
    "    dim = sigma.shape[0]\n",
    "    N = int(T / dt)  # 时间步数量\n",
    "    t_list = np.linspace(0, T, N + 1)\n",
    "    np.random.seed(seed)\n",
    "    # --- Bt=B0*(1+np.cos(2*np.pi*rand_k*t)) /2---\n",
    "    # 抽取 m 个场景的索引\n",
    "    # num_scenarios = joint_z_vectors.shape[0]\n",
    "    # scenario_indices = np.arange(num_scenarios)\n",
    "    # chosen_indices = np.random.choice(scenario_indices, p=p_dist, size=num_paths, replace=True)\n",
    "\n",
    "\n",
    "    B0=0.2\n",
    "    rand_k = np.random.normal(10, 30, sigma.shape[0]) # TODO: make k larger so fluctuate weekly or bi-weekly\n",
    "    # generate b_vectors, finally shape is (N, dim)\n",
    "    b_vectors = np.zeros((N, dim))\n",
    "    \n",
    "    # Create meshgrid for proper broadcasting: t (N,) and rand_k (dim,)\n",
    "    # We use t_list[:-1] to get N time steps (excluding the last one)\n",
    "    t_mesh, rand_k_mesh = np.meshgrid(t_list[:-1], rand_k, indexing='ij')\n",
    "    # Now t_mesh and rand_k_mesh both have shape (N, dim)\n",
    "    b_vectors = B0*(1 + 2*np.cos(2*np.pi*rand_k_mesh*t_mesh))/2\n",
    "\n",
    "    # --- 2. 模拟多维布朗运动 W ---\n",
    "    # 生成标准正态分布的增量\n",
    "    \n",
    "    normal_increments = np.random.normal(loc=0.0, scale=np.sqrt(dt), size=(num_paths, N, dim))\n",
    "    \n",
    "    W = np.zeros((num_paths, N + 1, dim))\n",
    "    # 通过对增量进行累积求和来构建布朗运动路径\n",
    "    W[:, 1:, :] = np.cumsum(normal_increments, axis=1)\n",
    "\n",
    "    # --- 3. 模拟股价路径 S ---\n",
    "    S = np.zeros((num_paths, N + 1, dim))\n",
    "\n",
    "    S[:, 0, :] = s0 * np.ones((num_paths, dim))\n",
    "\n",
    "    for i in range(N):\n",
    "        # 提取当前状态\n",
    "        current_S = S[:, i, :]\n",
    "        \n",
    "        # 布朗运动的增量 dW\n",
    "        dW = W[:, i + 1, :] - W[:, i, :]\n",
    "        \n",
    "        # --- 计算 SDE 的增量 dS ---\n",
    "        # 漂移项: b*dt\n",
    "        drift_term = b_vectors[i] * dt\n",
    "        \n",
    "        # 波动率项: σ * dW\n",
    "        # 使用矩阵乘法 (@)，并对 sigma 进行转置以匹配批量操作的维度\n",
    "        # (num_paths, dim) @ (dim, dim) -> (num_paths, dim)\n",
    "        vol_term = dW @ sigma.T\n",
    "        \n",
    "        # 逐元素乘法计算 dS\n",
    "        dS = current_S * (drift_term + vol_term)\n",
    "        \n",
    "        # 更新下一时间步的价格\n",
    "        S[:, i + 1, :] = current_S + dS\n",
    "    \n",
    "    # for each path, if any negative items in S, remove this path \n",
    "    for i in range(num_paths):\n",
    "        if np.any(S[i] < 0):\n",
    "            S = np.delete(S, i, axis=0)\n",
    "            W = np.delete(W, i, axis=0)\n",
    "    \n",
    "    \n",
    "    return S, t_list, b_vectors, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2414119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3025, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_gen, t_list_gen, b_vectors_gen, W_gen = sim_mkt_data_highdim(T=12, num_paths=100, s0=10, sigma=sigma_real, dt=1/252)\n",
    "prices_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18162073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data_to_df(prices, real_trade_dates):\n",
    "    \"\"\"\n",
    "    Converts a 2D numpy array of prices into a long-format pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        prices (np.ndarray): A 2D numpy array of shape (T, dim), where T is the\n",
    "                             number of time periods and dim is the number of stocks.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with columns: 'date', 'permno', 'ret', and 'prc'.\n",
    "                      'permno' is the stock identifier, from 1 to dim.\n",
    "    \"\"\"\n",
    "    T, dim = prices.shape\n",
    "    dates = real_trade_dates[-T:]\n",
    "    permnos = range(1, dim + 1)\n",
    "\n",
    "    # Create a wide DataFrame for prices\n",
    "    df_prc = pd.DataFrame(prices, index=dates, columns=permnos)\n",
    "    df_prc.index.name = 'date'\n",
    "    df_prc.columns.name = 'permno'\n",
    "\n",
    "    # Calculate returns\n",
    "    df_ret = df_prc.pct_change()\n",
    "\n",
    "    # Stack prices and returns to convert to long format\n",
    "    # dropna=False is important to keep all price entries, even with NaN returns for the first day\n",
    "    s_prc = df_prc.stack(dropna=False).rename('prc')\n",
    "    s_ret = df_ret.stack(dropna=False).rename('ret')\n",
    "\n",
    "    # Combine into a single DataFrame, aligning on the (date, permno) index\n",
    "    df = pd.concat([s_ret, s_prc], axis=1)\n",
    "\n",
    "    # Reset index to get 'date' and 'permno' as columns\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Reorder columns to the desired format\n",
    "    df = df[['date', 'permno', 'ret', 'prc']]\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['type'] = (df.groupby('date').ngroup() % 60) + 1\n",
    "    df['prc_adjusted'] = df['prc']\n",
    "    df['log_ret'] = df.groupby('permno')['prc'].transform(lambda x: np.log(x / x.shift(1)))\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b4d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = sim_data_to_df(prices_gen[0], df['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddf32474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>ret</th>\n",
       "      <th>prc</th>\n",
       "      <th>type</th>\n",
       "      <th>prc_adjusted</th>\n",
       "      <th>log_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>9.789018</td>\n",
       "      <td>2</td>\n",
       "      <td>9.789018</td>\n",
       "      <td>-0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.019481</td>\n",
       "      <td>9.897384</td>\n",
       "      <td>2</td>\n",
       "      <td>9.897384</td>\n",
       "      <td>-0.019674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.013432</td>\n",
       "      <td>9.888227</td>\n",
       "      <td>2</td>\n",
       "      <td>9.888227</td>\n",
       "      <td>-0.013523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>10.297934</td>\n",
       "      <td>2</td>\n",
       "      <td>10.297934</td>\n",
       "      <td>0.023384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>10.109208</td>\n",
       "      <td>2</td>\n",
       "      <td>10.109208</td>\n",
       "      <td>-0.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60475</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>16</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>39.044854</td>\n",
       "      <td>24</td>\n",
       "      <td>39.044854</td>\n",
       "      <td>0.005755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60476</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.013081</td>\n",
       "      <td>32.298023</td>\n",
       "      <td>24</td>\n",
       "      <td>32.298023</td>\n",
       "      <td>-0.013167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60477</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.021993</td>\n",
       "      <td>11.650680</td>\n",
       "      <td>24</td>\n",
       "      <td>11.650680</td>\n",
       "      <td>-0.022239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60478</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.022032</td>\n",
       "      <td>42.341205</td>\n",
       "      <td>24</td>\n",
       "      <td>42.341205</td>\n",
       "      <td>-0.022279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60479</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.018210</td>\n",
       "      <td>48.934574</td>\n",
       "      <td>24</td>\n",
       "      <td>48.934574</td>\n",
       "      <td>-0.018378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60460 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  permno       ret        prc  type  prc_adjusted   log_ret\n",
       "20     2012-12-27       1 -0.002906   9.789018     2      9.789018 -0.002911\n",
       "21     2012-12-27       2 -0.019481   9.897384     2      9.897384 -0.019674\n",
       "22     2012-12-27       3 -0.013432   9.888227     2      9.888227 -0.013523\n",
       "23     2012-12-27       4  0.023659  10.297934     2     10.297934  0.023384\n",
       "24     2012-12-27       5 -0.001127  10.109208     2     10.109208 -0.001127\n",
       "...           ...     ...       ...        ...   ...           ...       ...\n",
       "60475  2024-12-31      16  0.005771  39.044854    24     39.044854  0.005755\n",
       "60476  2024-12-31      17 -0.013081  32.298023    24     32.298023 -0.013167\n",
       "60477  2024-12-31      18 -0.021993  11.650680    24     11.650680 -0.022239\n",
       "60478  2024-12-31      19 -0.022032  42.341205    24     42.341205 -0.022279\n",
       "60479  2024-12-31      20 -0.018210  48.934574    24     48.934574 -0.018378\n",
       "\n",
       "[60460 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bd3983d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00398406, 0.00796813, 0.01195219, 0.01593625,\n",
       "       0.01992032, 0.02390438, 0.02788845, 0.03187251, 0.03585657,\n",
       "       0.03984064, 0.0438247 , 0.04780876, 0.05179283, 0.05577689,\n",
       "       0.05976096, 0.06374502, 0.06772908, 0.07171315, 0.07569721,\n",
       "       0.07968127, 0.08366534, 0.0876494 , 0.09163347, 0.09561753,\n",
       "       0.09960159, 0.10358566, 0.10756972, 0.11155378, 0.11553785,\n",
       "       0.11952191, 0.12350598, 0.12749004, 0.1314741 , 0.13545817,\n",
       "       0.13944223, 0.14342629, 0.14741036, 0.15139442, 0.15537849,\n",
       "       0.15936255, 0.16334661, 0.16733068, 0.17131474, 0.1752988 ,\n",
       "       0.17928287, 0.18326693, 0.187251  , 0.19123506, 0.19521912,\n",
       "       0.19920319, 0.20318725, 0.20717131, 0.21115538, 0.21513944,\n",
       "       0.21912351, 0.22310757, 0.22709163, 0.2310757 , 0.23505976,\n",
       "       0.23904382, 0.24302789, 0.24701195, 0.25099602, 0.25498008,\n",
       "       0.25896414, 0.26294821, 0.26693227, 0.27091633, 0.2749004 ,\n",
       "       0.27888446, 0.28286853, 0.28685259, 0.29083665, 0.29482072,\n",
       "       0.29880478, 0.30278884, 0.30677291, 0.31075697, 0.31474104,\n",
       "       0.3187251 , 0.32270916, 0.32669323, 0.33067729, 0.33466135,\n",
       "       0.33864542, 0.34262948, 0.34661355, 0.35059761, 0.35458167,\n",
       "       0.35856574, 0.3625498 , 0.36653386, 0.37051793, 0.37450199,\n",
       "       0.37848606, 0.38247012, 0.38645418, 0.39043825, 0.39442231,\n",
       "       0.39840637, 0.40239044, 0.4063745 , 0.41035857, 0.41434263,\n",
       "       0.41832669, 0.42231076, 0.42629482, 0.43027888, 0.43426295,\n",
       "       0.43824701, 0.44223108, 0.44621514, 0.4501992 , 0.45418327,\n",
       "       0.45816733, 0.46215139, 0.46613546, 0.47011952, 0.47410359,\n",
       "       0.47808765, 0.48207171, 0.48605578, 0.49003984, 0.4940239 ,\n",
       "       0.49800797, 0.50199203, 0.5059761 , 0.50996016, 0.51394422,\n",
       "       0.51792829, 0.52191235, 0.52589641, 0.52988048, 0.53386454,\n",
       "       0.53784861, 0.54183267, 0.54581673, 0.5498008 , 0.55378486,\n",
       "       0.55776892, 0.56175299, 0.56573705, 0.56972112, 0.57370518,\n",
       "       0.57768924, 0.58167331, 0.58565737, 0.58964143, 0.5936255 ,\n",
       "       0.59760956, 0.60159363, 0.60557769, 0.60956175, 0.61354582,\n",
       "       0.61752988, 0.62151394, 0.62549801, 0.62948207, 0.63346614,\n",
       "       0.6374502 , 0.64143426, 0.64541833, 0.64940239, 0.65338645,\n",
       "       0.65737052, 0.66135458, 0.66533865, 0.66932271, 0.67330677,\n",
       "       0.67729084, 0.6812749 , 0.68525896, 0.68924303, 0.69322709,\n",
       "       0.69721116, 0.70119522, 0.70517928, 0.70916335, 0.71314741,\n",
       "       0.71713147, 0.72111554, 0.7250996 , 0.72908367, 0.73306773,\n",
       "       0.73705179, 0.74103586, 0.74501992, 0.74900398, 0.75298805,\n",
       "       0.75697211, 0.76095618, 0.76494024, 0.7689243 , 0.77290837,\n",
       "       0.77689243, 0.78087649, 0.78486056, 0.78884462, 0.79282869,\n",
       "       0.79681275, 0.80079681, 0.80478088, 0.80876494, 0.812749  ,\n",
       "       0.81673307, 0.82071713, 0.8247012 , 0.82868526, 0.83266932,\n",
       "       0.83665339, 0.84063745, 0.84462151, 0.84860558, 0.85258964,\n",
       "       0.85657371, 0.86055777, 0.86454183, 0.8685259 , 0.87250996,\n",
       "       0.87649402, 0.88047809, 0.88446215, 0.88844622, 0.89243028,\n",
       "       0.89641434, 0.90039841, 0.90438247, 0.90836653, 0.9123506 ,\n",
       "       0.91633466, 0.92031873, 0.92430279, 0.92828685, 0.93227092,\n",
       "       0.93625498, 0.94023904, 0.94422311, 0.94820717, 0.95219124,\n",
       "       0.9561753 , 0.96015936, 0.96414343, 0.96812749, 0.97211155,\n",
       "       0.97609562, 0.98007968, 0.98406375, 0.98804781, 0.99203187,\n",
       "       0.99601594, 1.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68aab903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_sim_new(input_df, r=0.02, seed=42, start_date='2024-01-01', end_date='2024-12-31',\n",
    "                 beta=-3, num_stocks=20, plan_time=1/12):\n",
    "    # Step 1: Load data\n",
    "    \n",
    "    df = input_df\n",
    "    \n",
    "    # Sort by permno and date to ensure proper ordering for log return calculation\n",
    "    df = df.sort_values(['permno', 'date'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Calculate log returns for each stock\n",
    "    \n",
    "    \n",
    "    # Step 1: Find stocks with complete data from 2005-12-31 to 2015-01-01\n",
    "    initial_start = pd.to_datetime(start_date) - relativedelta(years=10)    \n",
    "    initial_end = pd.to_datetime(start_date) - pd.Timedelta(days=1)\n",
    "    \n",
    "    # Get stocks that have data in the initial period\n",
    "    initial_period_data = df[(df['date'] >= initial_start) & (df['date'] <= initial_end)]\n",
    "    \n",
    "    # Count trading days in the initial period for validation\n",
    "    total_trading_days = initial_period_data['date'].nunique()\n",
    "    # print(f\"Total trading days in initial period: {total_trading_days}\")\n",
    "    \n",
    "    # Find stocks with sufficient data coverage (at least 80% of trading days)\n",
    "    stock_coverage = initial_period_data.groupby('permno')['date'].nunique()\n",
    "    min_required_days = int(total_trading_days)  # Require at least 80% coverage\n",
    "    valid_stocks_initial = stock_coverage[stock_coverage >= min_required_days].index.tolist()\n",
    "    \n",
    "    # print(f\"Stocks with sufficient data in initial period: {len(valid_stocks_initial)}\")\n",
    "    \n",
    "    # Sample num_stocks stocks from those with complete initial data\n",
    "    np.random.seed(seed)  # For reproducibility\n",
    "    selected_stocks = np.sort(np.random.choice(valid_stocks_initial, num_stocks, replace=False))\n",
    "    \n",
    "    print(f\"Initially selected stocks: {selected_stocks}\")\n",
    "    \n",
    "    # Step 2: Process monthly data starting from 2015-01-01\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    month_starts = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    \n",
    "    current_stocks = selected_stocks.copy()\n",
    "    kara_wealth_list = [1]\n",
    "    drbc_wealth_list = [1]\n",
    "    drmv_wealth_list = [1]\n",
    "    for i, current_month in enumerate(tqdm(month_starts)):\n",
    "        # print(f\"\\nProcessing month {i+1}/{len(month_starts)}: {current_month}\")\n",
    "        \n",
    "        # Define time windows\n",
    "        train_start = current_month - relativedelta(years=10)\n",
    "        train_end = current_month - pd.Timedelta(days=1)\n",
    "        test_start = current_month\n",
    "        test_end = month_starts[i+1] - pd.Timedelta(days=1) if i+1 < len(month_starts) else pd.to_datetime(end_date)\n",
    "        \n",
    "        # print(f\"Previous 10 years: {train_start.date()} to {train_end.date()}\")\n",
    "        # print(f\"Next month: {test_start.date()} to {test_end.date()}\")\n",
    "        \n",
    "        prev_to_next_dates = df[(df['date'] >= train_start) & (df['date'] <= test_end)]['date'].nunique()\n",
    "        \n",
    "        # Efficiently find all stocks with 100% coverage using vectorized operations\n",
    "        # Get data for the entire period (train + test)\n",
    "        full_period_start = train_start\n",
    "        full_period_end = test_end\n",
    "        full_period_data = df[(df['date'] >= full_period_start) & (df['date'] <= full_period_end)]\n",
    "        full_period_stock_dates = full_period_data.groupby('permno')['date'].nunique()\n",
    "        all_valid_stocks = full_period_stock_dates[full_period_stock_dates >= prev_to_next_dates].index.values\n",
    "        \n",
    "        # Check which current stocks are still valid\n",
    "        valid_current_stocks = np.intersect1d(current_stocks, all_valid_stocks)\n",
    "        \n",
    "        # print(f\"Current stocks with 100% coverage: {len(valid_current_stocks)} out of {len(current_stocks)}\")\n",
    "        # print(f\"Total stocks available with 100% coverage: {len(all_valid_stocks)}\")\n",
    "        \n",
    "        # If we need to replace stocks to maintain 20 stocks\n",
    "        stocks_needed = num_stocks - len(valid_current_stocks)\n",
    "        \n",
    "        if stocks_needed > 0:\n",
    "            # print(f\"Need to find {stocks_needed} replacement stocks\")\n",
    "            \n",
    "            # Find replacement candidates (exclude currently valid stocks)\n",
    "            replacement_candidates = np.setdiff1d(all_valid_stocks, valid_current_stocks)\n",
    "            \n",
    "            # print(f\"Available replacement candidates: {len(replacement_candidates)}\")\n",
    "            # add to 20 stocks\n",
    "            stocks_to_add = np.random.choice(replacement_candidates, stocks_needed, replace=False)\n",
    "            # Use all available replacements, even if less than needed\n",
    "            current_stocks = np.sort(np.concatenate([valid_current_stocks, stocks_to_add]))\n",
    "\n",
    "        else:\n",
    "            current_stocks = valid_current_stocks\n",
    "            # print(\"All current stocks are valid, no replacement needed\")\n",
    "        \n",
    "        # print(f\"Final stock selection for this month: {current_stocks}\")\n",
    "        # print(f\"Number of stocks: {len(current_stocks)}\")\n",
    "        \n",
    "        # Get training data for the selected stocks\n",
    "        pretrain_data = df[(df['date'] >= train_start) & (df['date'] <= train_end) & \n",
    "                          (df['permno'].isin(current_stocks))]\n",
    "        drmv_weights = run_single_backtest_select_stocks(\n",
    "            training_data=pretrain_data,\n",
    "            selected_perms=current_stocks,\n",
    "            annual_target_return=0.105,\n",
    "            r=r)\n",
    "        length = len(pretrain_data) / len(current_stocks)\n",
    "        prev_sigma_start_dt = (train_start - relativedelta(months=1))\n",
    "        #prev_sigma_start_dt = (train_start - relativedelta(years=1))\n",
    "        to_get_B_data = df[(df['date'] >= prev_sigma_start_dt) & (df['date'] <= train_end) & \n",
    "                          (df['permno'].isin(current_stocks))]\n",
    "        matrix = compute_annualized_matrix_type(to_get_B_data, sigma_real)\n",
    "        ret_matrix = pretrain_data.pivot(index='date', columns='permno', values='ret')\n",
    "        ret_matrix = ret_matrix.fillna(0)\n",
    "        \n",
    "       \n",
    "        # use real sigma matrix (already annualized)\n",
    "        sigma_mat = sigma_real #np.linalg.cholesky(cov)\n",
    "        curr_data = df[(df['date'] <= test_end) & (df['date'] >= current_month)&(df['permno'].isin(current_stocks))]\n",
    "        dt = 1/length\n",
    "        t_list = np.linspace(0, 1, 252)\n",
    "        price_st = curr_data.pivot(index='date', columns='permno', values='prc_adjusted').fillna(method='ffill').values\n",
    "        curr_all_ret = price_st[-1] / price_st[0] - 1\n",
    "        yt = St_to_Yt_vectorized(price_st[np.newaxis, :, :], price_st[0], sigma_mat, r, t_list[1:int(len(curr_data)/20)+1]) # can be t_list[0:len(curr_data)]\n",
    "        k= solve_k_with_EL(matrix, r=r, sigma=sigma_mat, T=1, beta=beta, num_y=1000, seed=seed)\n",
    "\n",
    "        # calculate radius small delta (using 1 year, represents by T=1)\n",
    "        var = calculate_z_var(T=1, r=r, sigma=sigma_mat, B_support=matrix, p_dist=np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k)\n",
    "        small_delta_array = (np.random.normal(0, np.sqrt(var), size=100)**2)*(calculate_numerator(1, r, sigma_mat, matrix, np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k)/calculate_denominator(1, r, sigma_mat, matrix, np.ones(matrix.shape[0])/matrix.shape[0], beta=beta, k=k))\n",
    "        small_delta = np.percentile(small_delta_array, 95)/120\n",
    "        \n",
    "        # calculate delta_B (using 1 year, represents by T=1)\n",
    "        delta_B = compute_big_delta_star(matrix, r, 1, beta, small_delta, sigma_mat)\n",
    "        \n",
    "        month_r = np.power(1+r, 1/12)-1 \n",
    "        # add month_r to curr_all_ret for drmv\n",
    "        curr_ret_for_drmv = np.append(curr_all_ret, month_r)\n",
    "        daily_kara = 1\n",
    "        daily_drbc = 1\n",
    "        daily_r = np.power(1+r, 1/252)-1\n",
    "        # last day not trade since no price for next day\n",
    "        for j in range(1,curr_data['date'].nunique()):\n",
    "            kara_frac_daily = pi_fraction_exact(t=j/252, Yt=yt[0][j-1], T=plan_time, alpha=beta, r=r, sigma=sigma_mat,\n",
    "                        joint_z_vectors=matrix, p_dist=np.ones(matrix.shape[0])/matrix.shape[0],\n",
    "                        num_expectation_samples=5000, seed=seed)\n",
    "            drbc_frac_daily = pi_fraction_exact(t=j/252, Yt=yt[0][j-1], T=plan_time, alpha=beta, r=r, sigma=sigma_mat, \n",
    "                        joint_z_vectors=matrix+delta_B, p_dist=np.ones(matrix.shape[0])/matrix.shape[0],\n",
    "                        num_expectation_samples=5000, seed=seed)\n",
    "            daily_kara *= (1-kara_frac_daily.sum())*daily_r+np.dot(kara_frac_daily, price_st[j] / price_st[j-1] - 1)+1\n",
    "            daily_drbc *= (1-drbc_frac_daily.sum())*daily_r+np.dot(drbc_frac_daily, price_st[j] / price_st[j-1] - 1)+1\n",
    "            \n",
    "            \n",
    "        # kara_wealth_list.append((kara_wealth_list[-1]*(1-kara_frac.sum())*month_r+np.dot(kara_frac, curr_all_ret)+1)*kara_wealth_list[-1])\n",
    "        # drbc_wealth_list.append((drbc_wealth_list[-1]*(1-drbc_frac.sum())*month_r+np.dot(drbc_frac, curr_all_ret)+1)*drbc_wealth_list[-1])\n",
    "        drmv_wealth_list.append(drmv_wealth_list[-1]*(1+np.dot(drmv_weights, curr_ret_for_drmv)))\n",
    "        kara_wealth_list.append(daily_kara*kara_wealth_list[-1])\n",
    "        drbc_wealth_list.append(daily_drbc*drbc_wealth_list[-1])\n",
    "\n",
    "    return kara_wealth_list, drbc_wealth_list, drmv_wealth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71c71b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially selected stocks: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain_sim_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 128\u001b[0m, in \u001b[0;36mmain_sim_new\u001b[0;34m(input_df, r, seed, start_date, end_date, beta, num_stocks, plan_time)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# calculate radius small delta (using 1 year, represents by T=1)\u001b[39;00m\n\u001b[1;32m    127\u001b[0m var \u001b[38;5;241m=\u001b[39m calculate_z_var(T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, r\u001b[38;5;241m=\u001b[39mr, sigma\u001b[38;5;241m=\u001b[39msigma_mat, B_support\u001b[38;5;241m=\u001b[39mmatrix, p_dist\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], beta\u001b[38;5;241m=\u001b[39mbeta, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m--> 128\u001b[0m small_delta_array \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39msqrt(var), size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m(calculate_numerator(\u001b[38;5;241m1\u001b[39m, r, sigma_mat, matrix, np\u001b[38;5;241m.\u001b[39mones(matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], beta\u001b[38;5;241m=\u001b[39mbeta, k\u001b[38;5;241m=\u001b[39mk)\u001b[38;5;241m/\u001b[39m\u001b[43mcalculate_denominator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    129\u001b[0m small_delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(small_delta_array, \u001b[38;5;241m95\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m120\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# calculate delta_B (using 1 year, represents by T=1)\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/data/wulab/jiayi/drmv_drbc/calculate_delta.py:162\u001b[0m, in \u001b[0;36mcalculate_denominator\u001b[0;34m(T, r, sigma, B_support, p_dist, beta, k, m1, m2, seed)\u001b[0m\n\u001b[1;32m    152\u001b[0m vectors_B \u001b[38;5;241m=\u001b[39m g_prime2_vals\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, m2, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m grad_L2_tensor \u001b[38;5;66;03m# (n, m2, dim)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# --- 步骤 4: 使用 np.einsum 正确并高效地计算三重求和 ---\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# 这是此函数的关键修正点。\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# 我们要计算: Σ_i Σ_j Σ_k Σ_d (A_{kid} * B_{kjd})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# '->'  -> 输出。因为右边是空的，意味着对所有出现在左边但没在右边的\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m#          索引 (k, i, j, d) 进行求和，最终得到一个标量。\u001b[39;00m\n\u001b[0;32m--> 162\u001b[0m total_sum \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkid,kjd->\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors_B\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# --- 步骤 5: 应用最终的归一化因子 ---\u001b[39;00m\n\u001b[1;32m    165\u001b[0m final_result \u001b[38;5;241m=\u001b[39m total_sum \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m*\u001b[39m m1 \u001b[38;5;241m*\u001b[39m m2)\n",
      "File \u001b[0;32m/gpfs/data/wulab/jiayi/conda_envs/tabsyn/lib/python3.10/site-packages/numpy/_core/einsumfunc.py:1429\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m specified_out:\n\u001b[1;32m   1428\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m-> 1429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;66;03m# repeat default values here\u001b[39;00m\n\u001b[1;32m   1433\u001b[0m valid_einsum_kwargs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_sim_new(sim_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
