{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0077941b",
   "metadata": {},
   "source": [
    "\n",
    "# Empirical Shift via \\( \\Delta^\\*(B) \\) from Monte Carlo \\( H(B) \\)\n",
    "\n",
    "This notebook:\n",
    "1. Samples \\(n=120\\) points \\(B_i \\in \\mathbb R^{20}\\) i.i.d. from \\(\\mathcal N(0.05\\cdot \\mathbf 1,\\, 0.01^2 I)\\) and sets \\(P_0=P_n\\) (the empirical law).\n",
    "2. Defines\n",
    "\\[\n",
    "L_t(x,z) = \\exp\\!\\Big( (\\sigma^{-1}(x-r\\mathbf 1))^\\top z - \\tfrac12 \\lVert \\sigma^{-1}(x-r\\mathbf 1)\\rVert^2\\, t \\Big).\n",
    "\\]\n",
    "3. Computes\n",
    "\\[\n",
    "H(B) = \\int_{\\mathbb R^d} \\nabla_b L_T(B,y)\\; \\Big(\\mathbb E^{P_0}[L_T(B,y)]\\Big)^{\\frac{\\alpha}{1-\\alpha}} \\varphi_T(y)\\,dy\n",
    "= \\mathbb E_{Y\\sim \\mathcal N(0, TI)}\\!\\left[ \\nabla_b L_T(B,Y)\\,M(Y)\\right]\n",
    "\\]\n",
    "with Monte Carlo over \\(Y\\), where \\(M(y)=\\big(\\mathbb E^{P_0}[L_T(B,y)]\\big)^{\\frac{\\alpha}{1-\\alpha}}\\).\n",
    "4. Forms\n",
    "\\[\n",
    "\\Delta^\\*(B) = -\\frac{\\sqrt{\\delta}\\,H(B)}{\\sqrt{\\mathbb E^{P_0}\\big[\\lVert H(B)\\rVert_2^2\\big]}},\n",
    "\\qquad C_i = B_i + \\Delta^\\*(B_i),\n",
    "\\]\n",
    "and returns the empirical law of \\(\\{C_i\\}\\).\n",
    "\n",
    "All steps use vectorized NumPy for speed and numerical stability (log-mean-exp where helpful).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b21124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Parameters (edit as needed) ---\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(12345)  # reproducible\n",
    "\n",
    "# Dimensions / counts\n",
    "d = 20           # dimension\n",
    "n = 120          # number of samples for P0 = Pn\n",
    "m = 200          # Monte Carlo draws for Y in the y-integral\n",
    "\n",
    "# Model parameters\n",
    "mu_B = 0.05      # each entry of mean vector for B\n",
    "std_B = 0.01     # diag std dev for B\n",
    "r = 0.03         # risk-free rate\n",
    "T = 1.0          # time horizon\n",
    "alpha = -1.0     # user's setting\n",
    "delta = 0.006    # ambiguity radius used in Delta*\n",
    "\n",
    "# Volatility / diffusion matrix sigma (invertible).\n",
    "# Default: Identity. You can replace with any invertible matrix.\n",
    "sigma_matrix = np.eye(d, dtype=np.float64)\n",
    "sigma_inv = np.linalg.inv(sigma_matrix)\n",
    "\n",
    "# Ones vector\n",
    "ones = np.ones(d, dtype=np.float64)\n",
    "\n",
    "# Exponent for M(y)\n",
    "expo = alpha / (1.0 - alpha)  # for alpha = -1 this equals -1/2\n",
    "expo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd20cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Sample B_1,...,B_n from N(0.05*1, 0.01^2 * I) ---\n",
    "B = rng.normal(loc=mu_B, scale=std_B, size=(n, d)).astype(np.float64)\n",
    "\n",
    "# --- Monte Carlo Y ~ N(0, T I) for the y-integral ---\n",
    "Y = rng.normal(loc=0.0, scale=np.sqrt(T), size=(m, d)).astype(np.float64)\n",
    "\n",
    "# Utility: stable log-sum-exp and log-mean-exp\n",
    "def logsumexp(a, axis=None):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    amax = np.max(a, axis=axis, keepdims=True)\n",
    "    out = amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))\n",
    "    if axis is None:\n",
    "        return out.squeeze()\n",
    "    return np.squeeze(out, axis=axis)\n",
    "\n",
    "def logmeanexp(a, axis=None):\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    lse = logsumexp(a, axis=axis)\n",
    "    if axis is None:\n",
    "        N = a.size\n",
    "    else:\n",
    "        N = a.shape[axis]\n",
    "    return lse - np.log(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc58281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Precompute v_i = sigma^{-1} (B_i - r*1) for all i ---\n",
    "# We store row-wise as v_i^T for convenient matrix multiplies.\n",
    "V = (B - r*ones) @ sigma_inv.T                      # shape (n, d)\n",
    "V_norm2 = np.sum(V*V, axis=1)                       # shape (n,)\n",
    "\n",
    "# --- Compute log L_T(B_i, Y_j) = V_i dot Y_j - 0.5 * ||V_i||^2 * T ---\n",
    "logL = V @ Y.T - 0.5 * (V_norm2[:, None]) * T       # shape (n, m)\n",
    "\n",
    "# --- Compute M(Y_j) = ( E_{P0}[L_T(B, Y_j)] )^(alpha/(1-alpha)) ---\n",
    "# Use log-mean-exp over i to avoid numerical issues.\n",
    "log_mean_L_over_i = logmeanexp(logL, axis=0)        # shape (m,)\n",
    "M = np.exp(expo * log_mean_L_over_i)                # shape (m,)\n",
    "M.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2fa547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.27604443288885216)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Gradient: ∇_b L_T(B_i, Y_j) = L_T(B_i, Y_j) * (sigma^{-1})^T * (Y_j - T * v_i).\n",
    "# Hence H(B_i) = E_Y[ ∇_b L_T(B_i, Y) * M(Y) ] = (sigma^{-1})^T * E_Y[ L * M * (Y - T v_i) ]\n",
    "# We'll compute S_i := E_Y[ L * M * (Y - T v_i) ] row-wise, then H_i = S_i @ sigma_inv.\n",
    "\n",
    "# Weights W_{i,j} = (1/m) * L_T(B_i, Y_j) * M(Y_j)\n",
    "W = np.exp(logL) * (M[None, :]) / float(m)          # shape (n, m)\n",
    "\n",
    "# First term: sum_j W_{i,j} * Y_j  -> (n, d)\n",
    "WY = W @ Y                                          # (n, d)\n",
    "\n",
    "# Row-sum s_i = sum_j W_{i,j}\n",
    "s = np.sum(W, axis=1)                               # (n,)\n",
    "\n",
    "# Second term: T * s_i * v_i  -> (n, d)   (note v_i stored as rows in V)\n",
    "S = WY - (T * s)[:, None] * V                       # (n, d)\n",
    "\n",
    "# H_i = S_i @ sigma_inv\n",
    "H = S @ sigma_inv                                   # (n, d)\n",
    "\n",
    "# Denominator: sqrt( E^{P0}[ ||H(B)||_2^2 ] ) = sqrt( (1/n) * sum_i ||H_i||^2 )\n",
    "H_norm2 = np.sum(H*H, axis=1)                       # (n,)\n",
    "denom = np.sqrt(np.mean(H_norm2))\n",
    "\n",
    "denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1683f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Function: compute Delta^*(B) ---\n",
    "import numpy as np\n",
    "\n",
    "def compute_big_delta_star(B, r, T, alpha, delta, sigma_matrix, m=200, rng=None):\n",
    "    \"\"\"\n",
    "    Compute the empirical-shift direction Delta^*(B) using Monte Carlo over Y ~ N(0, T I).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    B : array-like, shape (n, d)\n",
    "        Input samples representing the empirical law P0 = Pn.\n",
    "    r : float\n",
    "        Risk-free rate.\n",
    "    T : float\n",
    "        Time horizon.\n",
    "    alpha : float\n",
    "        Robustness parameter.\n",
    "    delta : float\n",
    "        Ambiguity radius used in Delta*.\n",
    "    sigma_matrix : array-like, shape (d, d)\n",
    "        Invertible diffusion matrix.\n",
    "    m : int, optional (default=200)\n",
    "        Number of Monte Carlo draws for Y.\n",
    "    rng : numpy.random.Generator, optional\n",
    "        Random number generator for reproducibility. If None, a new Generator() is used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Delta : ndarray, shape (n, d)\n",
    "        The Delta^*(B) shifts for each row of B.\n",
    "    \"\"\"\n",
    "    B = np.asarray(B, dtype=np.float64)\n",
    "    if B.ndim != 2:\n",
    "        raise ValueError(\"B must be a 2D array of shape (n, d)\")\n",
    "    n, d = B.shape\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    sigma_matrix = np.asarray(sigma_matrix, dtype=np.float64)\n",
    "    sigma_inv = np.linalg.inv(sigma_matrix)\n",
    "\n",
    "    ones = np.ones(d, dtype=np.float64)\n",
    "    expo = alpha / (1.0 - alpha)\n",
    "\n",
    "    # Local stable log-sum-exp utilities\n",
    "    def _logsumexp(a, axis=None):\n",
    "        a = np.asarray(a, dtype=np.float64)\n",
    "        amax = np.max(a, axis=axis, keepdims=True)\n",
    "        out = amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))\n",
    "        if axis is None:\n",
    "            return out.squeeze()\n",
    "        return np.squeeze(out, axis=axis)\n",
    "\n",
    "    def _logmeanexp(a, axis=None):\n",
    "        a = np.asarray(a, dtype=np.float64)\n",
    "        lse = _logsumexp(a, axis=axis)\n",
    "        if axis is None:\n",
    "            N = a.size\n",
    "        else:\n",
    "            N = a.shape[axis]\n",
    "        return lse - np.log(N)\n",
    "\n",
    "    # Monte Carlo draws Y ~ N(0, T I)\n",
    "    Y = rng.normal(loc=0.0, scale=np.sqrt(T), size=(m, d)).astype(np.float64)\n",
    "\n",
    "    # v_i = sigma^{-1} (B_i - r*1)\n",
    "    V = (B - r * ones) @ sigma_inv.T                  # (n, d)\n",
    "    V_norm2 = np.sum(V * V, axis=1)                   # (n,)\n",
    "\n",
    "    # log L_T(B_i, Y_j)\n",
    "    logL = V @ Y.T - 0.5 * (V_norm2[:, None]) * T     # (n, m)\n",
    "\n",
    "    # M(Y_j) = ( E_{P0}[L_T(B, Y_j)] )^(alpha/(1-alpha))\n",
    "    log_mean_L_over_i = _logmeanexp(logL, axis=0)     # (m,)\n",
    "    M = np.exp(expo * log_mean_L_over_i)              # (m,)\n",
    "\n",
    "    # H(B_i) computation via weights\n",
    "    W = np.exp(logL) * (M[None, :]) / float(m)        # (n, m)\n",
    "    WY = W @ Y                                        # (n, d)\n",
    "    s = np.sum(W, axis=1)                             # (n,)\n",
    "    S = WY - (T * s)[:, None] * V                     # (n, d)\n",
    "    H = S @ sigma_inv                                 # (n, d)\n",
    "\n",
    "    # Denominator: sqrt( E^{P0}[ ||H(B)||_2^2 ] )\n",
    "    H_norm2 = np.sum(H * H, axis=1)\n",
    "    denom = np.sqrt(np.mean(H_norm2))\n",
    "\n",
    "    if denom == 0.0 or not np.isfinite(denom):\n",
    "        Delta = np.zeros_like(B)\n",
    "    else:\n",
    "        Delta = np.sqrt(delta) * H / denom\n",
    "\n",
    "    return Delta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52969237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: B (120, 20) H (120, 20) Delta (120, 20) C (120, 20)\n",
      "||H||_2 (avg over i): 0.27604443288885216\n",
      "Mean(B)[:5]: [0.04814551 0.04940982 0.05114938 0.05112614 0.04962243]\n",
      "Mean(C)[:5]: [0.07636861 0.03164736 0.0709019  0.04112399 0.03077643]\n",
      "Std(B) (per-dim) first 5: [0.00955588 0.0104546  0.0104167  0.01183611 0.00879081]\n",
      "Std(C) (per-dim) first 5: [0.00938612 0.0105131  0.01088511 0.01186915 0.00900725]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Delta^*(B_i) via function and shifted samples C_i ---\n",
    "Delta = compute_delta_star(\n",
    "    B=B,\n",
    "    r=r,\n",
    "    T=T,\n",
    "    alpha=alpha,\n",
    "    delta=delta,\n",
    "    sigma_matrix=sigma_matrix,\n",
    "    m=m,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "C = B + Delta\n",
    "\n",
    "# Basic sanity checks\n",
    "B_mean = B.mean(axis=0)\n",
    "C_mean = C.mean(axis=0)\n",
    "B_std = B.std(axis=0, ddof=1)\n",
    "C_std = C.std(axis=0, ddof=1)\n",
    "\n",
    "print(\"Shapes: B\", B.shape, \"Delta\", Delta.shape, \"C\", C.shape)\n",
    "print(\"Mean(B)[:5]:\", B_mean[:5])\n",
    "print(\"Mean(C)[:5]:\", C_mean[:5])\n",
    "print(\"Std(B) (per-dim) first 5:\", B_std[:5])\n",
    "print(\"Std(C) (per-dim) first 5:\", C_std[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4572bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02895747, -0.01770298,  0.01894733, ...,  0.01114293,\n",
       "         0.02512816,  0.0165398 ],\n",
       "       [ 0.02746001, -0.01797975,  0.02026449, ...,  0.00929966,\n",
       "         0.02394371,  0.01600569],\n",
       "       [ 0.02928585, -0.01836085,  0.02085612, ...,  0.01026428,\n",
       "         0.0244544 ,  0.0152185 ],\n",
       "       ...,\n",
       "       [ 0.02698868, -0.01771915,  0.02204272, ...,  0.00975391,\n",
       "         0.02423734,  0.01311033],\n",
       "       [ 0.02776239, -0.01898411,  0.02003331, ...,  0.01034894,\n",
       "         0.02515572,  0.01546593],\n",
       "       [ 0.02905986, -0.01818727,  0.02000468, ...,  0.00927049,\n",
       "         0.02372911,  0.01710059]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328618d",
   "metadata": {},
   "source": [
    "\n",
    "### Notes on \\(\\sigma\\)\n",
    "\n",
    "- This notebook defaults to \\(\\sigma=I_d\\). To use a general invertible \\(\\sigma\\), set:\n",
    "  ```python\n",
    "  sigma_matrix = <your dxd invertible matrix>\n",
    "  sigma_inv = np.linalg.inv(sigma_matrix)\n",
    "  ```\n",
    "- All formulas adapt automatically; we only ever use \\(\\sigma^{-1}\\) and \\((\\sigma^{-1})^\\top\\).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
